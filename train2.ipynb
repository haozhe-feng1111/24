{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b09255-c46f-42b2-9e92-5e64861efa43",
   "metadata": {},
   "source": [
    "# Qwen2.5å¾®è°ƒå®æˆ˜ï¼š24ç‚¹æ¸¸æˆæ¨ç†é£æ ¼èŠå¤©\n",
    "\n",
    "[![](https://raw.githubusercontent.com/SwanHubX/assets/main/badge1.svg)](https://swanlab.cn/@ZeyiLin/qwen2.5-sft-24game/overview)\n",
    "\n",
    "- **åŸºç¡€æ¨¡å‹**ï¼š[Qwen2.5-0.5B](https://modelscope.cn/models/Qwen/Qwen2.5-0.5B/summary)\n",
    "- **å¾®è°ƒåæ¨¡å‹**ï¼š[Qwen2.5-0.5b-24game-sft](https://modelscope.cn/models/testUser/Qwen2.5-0.5b-24game-sft/summary)\n",
    "- **æ•°æ®é›†**ï¼š24ç‚¹æ¸¸æˆæ¨ç†æ•°æ®é›†\n",
    "- **SwanLab**ï¼š[qwen2.5-sft-24game](https://swanlab.cn/@ZeyiLin/qwen2.5-sft-24game/runs/agps0dkifth5l1xytcdyk/chart)\n",
    "- **å¾®è°ƒæ–¹å¼**ï¼šå…¨å‚æ•°å¾®è°ƒã€LoRAå¾®è°ƒ\n",
    "- **æ¨ç†é£æ ¼**ï¼šè¯¦ç»†åˆ†ææ¨ç†é£æ ¼\n",
    "- **ç®—åŠ›è¦æ±‚**ï¼š\n",
    "  - **å…¨å‚æ•°å¾®è°ƒ**ï¼š16GBæ˜¾å­˜\n",
    "  - **LoRAå¾®è°ƒ**ï¼š16GBæ˜¾å­˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4fa4a-03a4-4bdb-b593-b50d2ebbb931",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42630f8a-e3d2-4972-9a44-a36aec69675f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swanlab in c:\\users\\10563\\anaconda3\\lib\\site-packages (0.6.7)\n",
      "Requirement already satisfied: boto3>=1.35.49 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (1.39.14)\n",
      "Requirement already satisfied: botocore in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (1.39.14)\n",
      "Requirement already satisfied: click in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (8.1.7)\n",
      "Requirement already satisfied: platformdirs>=4.2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (5.9.0)\n",
      "Requirement already satisfied: pydantic>=2.9.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.11.7)\n",
      "Requirement already satisfied: pyecharts>=2.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.0.8)\n",
      "Requirement already satisfied: pynvml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (12.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.28.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.6.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (13.7.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (75.1.0)\n",
      "Requirement already satisfied: swankit==0.2.4 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (0.2.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.2.3)\n",
      "Requirement already satisfied: wrapt>=1.17.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (1.17.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from boto3>=1.35.49->swanlab) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from boto3>=1.35.49->swanlab) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from botocore->swanlab) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (0.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pyecharts>=2.0.0->swanlab) (3.1.4)\n",
      "Requirement already satisfied: prettytable in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pyecharts>=2.0.0->swanlab) (3.16.0)\n",
      "Requirement already satisfied: simplejson in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pyecharts>=2.0.0->swanlab) (3.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.28.0->swanlab) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.28.0->swanlab) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.28.0->swanlab) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.6.0->swanlab) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.6.0->swanlab) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from click->swanlab) (0.4.6)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pynvml->swanlab) (12.575.51)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->swanlab) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore->swanlab) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from jinja2->pyecharts>=2.0.0->swanlab) (2.1.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\10563\\anaconda3\\lib\\site-packages (from prettytable->pyecharts>=2.0.0->swanlab) (0.2.5)\n",
      "Requirement already satisfied: modelscope==1.22.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (1.22.0)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from modelscope==1.22.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from modelscope==1.22.0) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from modelscope==1.22.0) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.25->modelscope==1.22.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.25->modelscope==1.22.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.25->modelscope==1.22.0) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->modelscope==1.22.0) (0.4.6)\n",
      "Requirement already satisfied: transformers in c:\\users\\10563\\anaconda3\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (0.34.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: datasets==3.2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (0.34.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets==3.2.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas->datasets==3.2.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas->datasets==3.2.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.16.0)\n",
      "Requirement already satisfied: peft in c:\\users\\10563\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (1.7.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (0.34.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
      "Requirement already satisfied: accelerate in c:\\users\\10563\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (0.34.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Requirement already satisfied: pandas in c:\\users\\10563\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: addict in c:\\users\\10563\\anaconda3\\lib\\site-packages (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install swanlab\n",
    "!pip install modelscope==1.22.0\n",
    "!pip install transformers\n",
    "!pip install datasets==3.2.0\n",
    "!pip install peft\n",
    "!pip install accelerate\n",
    "!pip install pandas\n",
    "!pip install addict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73ce7d-54a9-4928-9b27-c58c68c090d7",
   "metadata": {},
   "source": [
    "## 2. ä¸‹è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0912c-ab6e-4d4d-95b5-ba9e11687d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å·²å‡†å¤‡å®Œæ¯•ï¼Œè®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†åˆ«ä¸º train_data.json å’Œ test_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac44ba5-45d2-4e43-a906-2e4421b72114",
   "metadata": {},
   "source": [
    "## 3. ç™»å½•SwanLab\n",
    "1. å‰å¾€[swanlab](https://swanlab.cn/space/~/settings)å¤åˆ¶ä½ çš„API Keyï¼Œç²˜è´´åˆ°ä¸‹é¢çš„ä»£ç ä¸­\n",
    "2. å¦‚æœä½ ä¸å¸Œæœ›å°†ç™»å½•ä¿¡æ¯ä¿å­˜åˆ°è¯¥è®¡ç®—æœºä¸­ï¼Œå¯å°†`save=True`å»æ‰ï¼ˆæ¯æ¬¡è¿è¡Œè®­ç»ƒéœ€è¦é‡æ–°æ‰§è¡Œä¸‹é¢çš„ä»£ç å—ï¼‰\n",
    "3. è®­ç»ƒé¡¹ç›®åç§°å·²è®¾ç½®ä¸º \"qwen3-sft-24game\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5cbc21-ae61-40fd-ae38-843b774fe82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import swanlab\n",
    "\n",
    "swanlab.login(api_key=\"G091Sp6B1xT6JfwsVZhCx\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43e7f4-976b-46ec-ab63-febeac40a3ce",
   "metadata": {},
   "source": [
    "## 4. å¼€å¯24ç‚¹æ¸¸æˆæ¨¡å‹å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c451e2e-8542-404c-9eab-8fd610bf8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import os\n",
    "import swanlab\n",
    "\n",
    "os.environ[\"SWANLAB_PROJECT\"]=\"qwen2.5-sft-24game\"\n",
    "PROMPT = \"ä½ æ˜¯ä¸€ä¸ª24ç‚¹æ¸¸æˆä¸“å®¶ï¼Œæ“…é•¿åˆ†ææ•°å­—ç»„åˆå¹¶æ‰¾å‡ºè¿ç®—æ–¹æ¡ˆã€‚ä½ éœ€è¦æ ¹æ®ç”¨æˆ·ç»™å‡ºçš„æ•°å­—ï¼Œè¯¦ç»†åˆ†æè§£é¢˜æ€è·¯å’Œè¿‡ç¨‹ï¼Œæœ€ç»ˆç»™å‡ºèƒ½å¤Ÿå¾—åˆ°24çš„è¿ç®—æ–¹æ¡ˆã€‚\"\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "swanlab.config.update({\n",
    "    \"model\": \"Qwen/Qwen2.5-0.5B\",\n",
    "    \"prompt\": PROMPT,\n",
    "    \"data_max_length\": MAX_LENGTH,\n",
    "    })\n",
    "\n",
    "def dataset_jsonl_transfer(origin_path, new_path):\n",
    "    \"\"\"\n",
    "    å°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸ºå¤§æ¨¡å‹å¾®è°ƒæ‰€éœ€æ•°æ®æ ¼å¼çš„æ–°æ•°æ®é›†\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # è¯»å–åŸå§‹JSONæ–‡ä»¶\n",
    "    with open(origin_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # å¤„ç†æ¯ä¸ªå¯¹è¯\n",
    "    for item in data:\n",
    "        conversation = item[\"messages\"]\n",
    "        user_content = conversation[0][\"content\"]  # ç”¨æˆ·é—®é¢˜\n",
    "        assistant_content = conversation[1][\"content\"]  # åŠ©æ‰‹å›ç­”\n",
    "        \n",
    "        message = {\n",
    "            \"instruction\": PROMPT,\n",
    "            \"input\": user_content,\n",
    "            \"output\": assistant_content,\n",
    "        }\n",
    "        messages.append(message)\n",
    "\n",
    "    # ä¿å­˜é‡æ„åçš„JSONLæ–‡ä»¶\n",
    "    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for message in messages:\n",
    "            file.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def process_func(example):\n",
    "    \"\"\"\n",
    "    å°†æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†\n",
    "    \"\"\" \n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\n{PROMPT}<|im_end|>\\n<|im_start|>user\\n{example['input']}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = (\n",
    "        instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    )\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:  # åšä¸€ä¸ªæˆªæ–­\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}   \n",
    "\n",
    "\n",
    "def predict(messages, model, tokenizer):\n",
    "    device = \"cuda\"\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=MAX_LENGTH,\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response\n",
    "\n",
    "# åœ¨modelscopeä¸Šä¸‹è½½Qwenæ¨¡å‹åˆ°æœ¬åœ°ç›®å½•ä¸‹\n",
    "model_dir = snapshot_download(\"Qwen/Qwen2.5-0.5B\", cache_dir=\"./\", revision=\"master\")\n",
    "\n",
    "# TransformersåŠ è½½æ¨¡å‹æƒé‡\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model.enable_input_require_grads()  # å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹æ—¶ï¼Œè¦æ‰§è¡Œè¯¥æ–¹æ³•\n",
    "\n",
    "# åŠ è½½ã€å¤„ç†æ•°æ®é›†å’Œæµ‹è¯•é›†\n",
    "train_dataset_path = \"train_data.json\"\n",
    "test_dataset_path = \"test_data.json\"\n",
    "\n",
    "train_jsonl_new_path = \"train_format.jsonl\"\n",
    "test_jsonl_new_path = \"val_format.jsonl\"\n",
    "\n",
    "if not os.path.exists(train_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)\n",
    "if not os.path.exists(test_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(test_dataset_path, test_jsonl_new_path)\n",
    "\n",
    "# å¾—åˆ°è®­ç»ƒé›†\n",
    "train_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)\n",
    "\n",
    "# å¾—åˆ°éªŒè¯é›†\n",
    "eval_df = pd.read_json(test_jsonl_new_path, lines=True)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "eval_dataset = eval_ds.map(process_func, remove_columns=eval_ds.column_names)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen2.5-0.5B-24game\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=400,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"swanlab\",\n",
    "    run_name=\"qwen2.5-0.5B-24game\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ç”¨æµ‹è¯•é›†çš„å‰3æ¡ï¼Œä¸»è§‚çœ‹æ¨¡å‹\n",
    "test_df = pd.read_json(test_jsonl_new_path, lines=True)[:3]\n",
    "\n",
    "test_text_list = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    instruction = row['instruction']\n",
    "    input_value = row['input']\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"}\n",
    "    ]\n",
    "\n",
    "    response = predict(messages, model, tokenizer)\n",
    "\n",
    "    response_text = f\"\"\"\n",
    "    Question: {input_value}\n",
    "\n",
    "    LLM:{response}\n",
    "    \"\"\"\n",
    "    \n",
    "    test_text_list.append(swanlab.Text(response_text))\n",
    "    print(response_text)\n",
    "\n",
    "swanlab.log({\"Prediction\": test_text_list})\n",
    "\n",
    "swanlab.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sl54o3ag9dq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRAå¾®è°ƒç‰ˆæœ¬ - æ”¯æŒæ›´å¤§æ¨¡å‹åœ¨T4ä¸Šè®­ç»ƒ\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import os\n",
    "import swanlab\n",
    "\n",
    "# =============é…ç½®å‚æ•°============= \n",
    "# æ¨¡å‹é€‰æ‹©ï¼šå¯ä»¥é€‰æ‹©ä¸åŒå¤§å°çš„æ¨¡å‹\n",
    "MODEL_OPTIONS = {\n",
    "    \"qwen2.5-0.5b\": \"Qwen/Qwen2.5-0.5B\", \n",
    "    \"qwen2.5-1.5b\": \"Qwen/Qwen2.5-1.5B\",\n",
    "    \"qwen2.5-3b\": \"Qwen/Qwen2.5-3B\", \n",
    "    \"qwen2.5-7b\": \"Qwen/Qwen2.5-7B\"\n",
    "}\n",
    "\n",
    "# é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹\n",
    "SELECTED_MODEL = \"qwen2.5-7b\"  # æ”¹ä¸º7Bæ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„æ¨ç†èƒ½åŠ›\n",
    "MODEL_NAME = MODEL_OPTIONS[SELECTED_MODEL]\n",
    "\n",
    "# è®­ç»ƒæ¨¡å¼é…ç½®\n",
    "USE_LORA = True  # æ˜¯å¦ä½¿ç”¨LoRAå¾®è°ƒ\n",
    "USE_QUANTIZATION = True  # æ˜¯å¦ä½¿ç”¨é‡åŒ–ï¼ˆ4bitï¼‰æ¥è¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜\n",
    "\n",
    "# LoRAé…ç½®\n",
    "LORA_CONFIG = {\n",
    "    \"r\": 16,  # LoRA rankï¼Œå½±å“æ¨¡å‹è¡¨è¾¾èƒ½åŠ›\n",
    "    \"lora_alpha\": 32,  # LoRAç¼©æ”¾å‚æ•°\n",
    "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],  # Qwen2.5çš„attentionå’ŒMLPå±‚\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\"\n",
    "}\n",
    "\n",
    "# è®­ç»ƒå‚æ•°é…ç½®  \n",
    "TRAINING_CONFIG = {\n",
    "    \"output_dir\": f\"./output/{SELECTED_MODEL}-24game-lora\",\n",
    "    \"per_device_train_batch_size\": 1,  # T4æ˜¾å­˜é™åˆ¶ï¼Œä½¿ç”¨å°batch\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 8,  # å¢åŠ æ¢¯åº¦ç´¯ç§¯æ¥æ¨¡æ‹Ÿæ›´å¤§batch\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 50,\n",
    "    \"logging_steps\": 10,\n",
    "    \"num_train_epochs\": 3,  # å¢åŠ è®­ç»ƒè½®æ•°\n",
    "    \"save_steps\": 200,\n",
    "    \"learning_rate\": 2e-4,  # LoRAé€šå¸¸éœ€è¦æ›´é«˜å­¦ä¹ ç‡\n",
    "    \"warmup_steps\": 100,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"save_on_each_node\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"dataloader_pin_memory\": False,  # èŠ‚çœæ˜¾å­˜\n",
    "    \"report_to\": \"swanlab\",\n",
    "    \"run_name\": f\"{SELECTED_MODEL}-24game-lora\",\n",
    "}\n",
    "\n",
    "# å…¶ä»–é…ç½®\n",
    "os.environ[\"SWANLAB_PROJECT\"] = \"qwen2.5-sft-24game-lora\"\n",
    "PROMPT = \"ä½ æ˜¯ä¸€ä¸ª24ç‚¹æ¸¸æˆä¸“å®¶ï¼Œæ“…é•¿åˆ†ææ•°å­—ç»„åˆå¹¶æ‰¾å‡ºè¿ç®—æ–¹æ¡ˆã€‚ä½ éœ€è¦æ ¹æ®ç”¨æˆ·ç»™å‡ºçš„æ•°å­—ï¼Œè¯¦ç»†åˆ†æè§£é¢˜æ€è·¯å’Œè¿‡ç¨‹ï¼Œæœ€ç»ˆç»™å‡ºèƒ½å¤Ÿå¾—åˆ°24çš„è¿ç®—æ–¹æ¡ˆã€‚\"\n",
    "MAX_LENGTH = 1024  # å‡å°‘åºåˆ—é•¿åº¦èŠ‚çœæ˜¾å­˜\n",
    "\n",
    "# æ›´æ–°SwanLabé…ç½®\n",
    "swanlab.config.update({\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"use_lora\": USE_LORA,\n",
    "    \"use_quantization\": USE_QUANTIZATION,\n",
    "    \"lora_config\": LORA_CONFIG,\n",
    "    \"training_config\": TRAINING_CONFIG,\n",
    "    \"data_max_length\": MAX_LENGTH,\n",
    "})\n",
    "\n",
    "print(f\"é€‰æ‹©çš„æ¨¡å‹: {MODEL_NAME}\")\n",
    "print(f\"ä½¿ç”¨LoRA: {USE_LORA}\")\n",
    "print(f\"ä½¿ç”¨é‡åŒ–: {USE_QUANTIZATION}\")\n",
    "print(f\"é¢„è®¡æ˜¾å­˜éœ€æ±‚: ~12-14GB (ç›¸æ¯”å…¨å‚æ•°å¾®è°ƒ7Béœ€è¦40GB+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apv1nf6a9yv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡å‹åŠ è½½å’ŒLoRAé…ç½®\n",
    "def load_model_and_tokenizer():\n",
    "    \"\"\"åŠ è½½æ¨¡å‹å’Œtokenizerï¼Œæ”¯æŒé‡åŒ–å’ŒLoRA\"\"\"\n",
    "    \n",
    "    # ä¸‹è½½æ¨¡å‹\n",
    "    print(f\"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {MODEL_NAME}\")\n",
    "    model_dir = snapshot_download(MODEL_NAME, cache_dir=\"./\", revision=\"master\")\n",
    "    \n",
    "    # åŠ è½½tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # ç¡®ä¿æœ‰pad_token\n",
    "    \n",
    "    # é…ç½®é‡åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "    quantization_config = None\n",
    "    if USE_QUANTIZATION:\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,  # 4bité‡åŒ–\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,  # è®¡ç®—ç±»å‹\n",
    "            bnb_4bit_quant_type=\"nf4\",  # é‡åŒ–ç±»å‹\n",
    "            bnb_4bit_use_double_quant=True,  # åŒé‡é‡åŒ–ï¼Œè¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜\n",
    "        )\n",
    "        print(\"å¯ç”¨4bité‡åŒ–\")\n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",  # è‡ªåŠ¨åˆ†é…GPU\n",
    "        torch_dtype=torch.bfloat16 if not USE_QUANTIZATION else None,\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"flash_attention_2\" if torch.cuda.is_available() else None,  # ä½¿ç”¨Flash AttentionåŠ é€Ÿ\n",
    "    )\n",
    "    \n",
    "    # å‡†å¤‡LoRAå¾®è°ƒ\n",
    "    if USE_LORA:\n",
    "        print(\"é…ç½®LoRA...\")\n",
    "        \n",
    "        # å¦‚æœä½¿ç”¨é‡åŒ–ï¼Œéœ€è¦å‡†å¤‡æ¨¡å‹\n",
    "        if USE_QUANTIZATION:\n",
    "            model = prepare_model_for_kbit_training(model)\n",
    "        \n",
    "        # åˆ›å»ºLoRAé…ç½®\n",
    "        lora_config = LoraConfig(**LORA_CONFIG)\n",
    "        \n",
    "        # åº”ç”¨LoRA\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        \n",
    "        # æ‰“å°å¯è®­ç»ƒå‚æ•°ç»Ÿè®¡\n",
    "        model.print_trainable_parameters()\n",
    "    else:\n",
    "        # å…¨å‚æ•°å¾®è°ƒéœ€è¦å¯ç”¨è¾“å…¥æ¢¯åº¦\n",
    "        model.enable_input_require_grads()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "model, tokenizer = load_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hgknw2l18oh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å¤„ç†å‡½æ•°ï¼ˆä¸åŸç‰ˆç›¸åŒï¼Œä½†åšäº†ä¸€äº›ä¼˜åŒ–ï¼‰\n",
    "def dataset_jsonl_transfer(origin_path, new_path):\n",
    "    \"\"\"å°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸ºå¤§æ¨¡å‹å¾®è°ƒæ‰€éœ€æ•°æ®æ ¼å¼çš„æ–°æ•°æ®é›†\"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    with open(origin_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    for item in data:\n",
    "        conversation = item[\"messages\"]\n",
    "        user_content = conversation[0][\"content\"]\n",
    "        assistant_content = conversation[1][\"content\"]\n",
    "        \n",
    "        message = {\n",
    "            \"instruction\": PROMPT,\n",
    "            \"input\": user_content,\n",
    "            \"output\": assistant_content,\n",
    "        }\n",
    "        messages.append(message)\n",
    "    \n",
    "    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for message in messages:\n",
    "            file.write(json.dumps(message, ensure_ascii=False) + \"\\\\n\")\n",
    "\n",
    "def process_func(example):\n",
    "    \"\"\"å°†æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œé’ˆå¯¹LoRAä¼˜åŒ–\"\"\"\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    \n",
    "    # æ„å»ºè¾“å…¥åºåˆ—\n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\\\n{PROMPT}<|im_end|>\\\\n<|im_start|>user\\\\n{example['input']}<|im_end|>\\\\n<|im_start|>assistant\\\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    \n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    \n",
    "    # æˆªæ–­åˆ°æœ€å¤§é•¿åº¦\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    \n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "def predict(messages, model, tokenizer):\n",
    "    \"\"\"é¢„æµ‹å‡½æ•°ï¼Œæ”¯æŒLoRAæ¨¡å‹\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=512,  # é™ä½ç”Ÿæˆé•¿åº¦èŠ‚çœæ˜¾å­˜\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response\n",
    "\n",
    "print(\"æ•°æ®å¤„ç†å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "et94fxq37xt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®åŠ è½½å’Œè®­ç»ƒæ‰§è¡Œ\n",
    "# æ•°æ®è·¯å¾„\n",
    "train_dataset_path = \"train_data.json\"\n",
    "test_dataset_path = \"test_data.json\"\n",
    "train_jsonl_new_path = \"train_format_lora.jsonl\"\n",
    "test_jsonl_new_path = \"val_format_lora.jsonl\"\n",
    "\n",
    "# è½¬æ¢æ•°æ®æ ¼å¼\n",
    "if not os.path.exists(train_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)\n",
    "if not os.path.exists(test_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(test_dataset_path, test_jsonl_new_path)\n",
    "\n",
    "# åŠ è½½å’Œå¤„ç†æ•°æ®é›†\n",
    "print(\"åŠ è½½è®­ç»ƒæ•°æ®...\")\n",
    "train_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)\n",
    "\n",
    "print(\"åŠ è½½éªŒè¯æ•°æ®...\")\n",
    "eval_df = pd.read_json(test_jsonl_new_path, lines=True)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "eval_dataset = eval_ds.map(process_func, remove_columns=eval_ds.column_names)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}\")\n",
    "print(f\"éªŒè¯é›†å¤§å°: {len(eval_dataset)}\")\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒå‚æ•°\n",
    "args = TrainingArguments(**TRAINING_CONFIG)\n",
    "\n",
    "# åˆ›å»ºæ•°æ®æ•´ç†å™¨\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒå™¨\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "print(\"å¼€å§‹LoRAå¾®è°ƒè®­ç»ƒ...\")\n",
    "print(f\"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}\")\n",
    "print(f\"é¢„è®¡è®­ç»ƒæ—¶é—´: ~2-4å°æ—¶ (å–å†³äºæ•°æ®é‡)\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ä¿å­˜LoRAæƒé‡\n",
    "if USE_LORA:\n",
    "    print(\"ä¿å­˜LoRAæƒé‡...\")\n",
    "    model.save_pretrained(f\"./output/{SELECTED_MODEL}-24game-lora-weights\")\n",
    "    tokenizer.save_pretrained(f\"./output/{SELECTED_MODEL}-24game-lora-weights\")\n",
    "\n",
    "print(\"è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wdivfysgx9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡å‹æµ‹è¯•å’Œæ•ˆæœéªŒè¯\n",
    "print(\"å¼€å§‹æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹...\")\n",
    "\n",
    "# æµ‹è¯•æ•°æ®\n",
    "test_df = pd.read_json(test_jsonl_new_path, lines=True)[:3]\n",
    "test_text_list = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    instruction = row['instruction']\n",
    "    input_value = row['input']\n",
    "    expected_output = row['output']\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"}\n",
    "    ]\n",
    "\n",
    "    print(f\"\\\\n=== æµ‹è¯• {index + 1} ===\")\n",
    "    print(f\"é—®é¢˜: {input_value}\")\n",
    "    \n",
    "    # ç”Ÿæˆå›ç­”\n",
    "    response = predict(messages, model, tokenizer)\n",
    "    \n",
    "    print(f\"æ¨¡å‹å›ç­”: {response}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response_text = f\"\"\"\n",
    "æµ‹è¯• {index + 1}:\n",
    "é—®é¢˜: {input_value}\n",
    "\n",
    "LoRAå¾®è°ƒæ¨¡å‹å›ç­”:\n",
    "{response}\n",
    "\n",
    "åŸå§‹è®­ç»ƒæ•°æ®ç­”æ¡ˆ:\n",
    "{expected_output[:200]}...\n",
    "\"\"\"\n",
    "    \n",
    "    test_text_list.append(swanlab.Text(response_text))\n",
    "\n",
    "# è®°å½•åˆ°SwanLab\n",
    "swanlab.log({\"LoRA_Predictions\": test_text_list})\n",
    "\n",
    "# æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\\\nå½“å‰GPUæ˜¾å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"å³°å€¼GPUæ˜¾å­˜ä½¿ç”¨: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "print(\"\\\\n=== LoRAå¾®è°ƒè®­ç»ƒæ€»ç»“ ===\")\n",
    "print(f\"åŸºç¡€æ¨¡å‹: {MODEL_NAME}\")\n",
    "print(f\"è®­ç»ƒæ–¹å¼: {'LoRAå¾®è°ƒ' if USE_LORA else 'å…¨å‚æ•°å¾®è°ƒ'}\")\n",
    "print(f\"æ˜¯å¦é‡åŒ–: {USE_QUANTIZATION}\")\n",
    "print(f\"LoRA rank: {LORA_CONFIG['r']}\")\n",
    "print(f\"ç›®æ ‡æ¨¡å—: {LORA_CONFIG['target_modules']}\")\n",
    "print(f\"é¢„æœŸæ•ˆæœ: 7Bæ¨¡å‹åº”è¯¥å…·å¤‡æ›´å¼ºçš„æ•°å­¦æ¨ç†èƒ½åŠ›\")\n",
    "\n",
    "swanlab.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vxek8bcjvgg",
   "metadata": {},
   "source": [
    "## LoRAå¾®è°ƒä½¿ç”¨æŒ‡å—å’Œä¼˜åŒ–å»ºè®®\n",
    "\n",
    "### ğŸ“Š æ˜¾å­˜å¯¹æ¯”\n",
    "- **å…¨å‚æ•°å¾®è°ƒ7B**: éœ€è¦40GB+ æ˜¾å­˜  \n",
    "- **LoRA + 4bité‡åŒ–**: ä»…éœ€12-14GBæ˜¾å­˜ âœ… \n",
    "- **T4 GPU**: 16GBæ˜¾å­˜ âœ… å®Œå…¨å¯ç”¨\n",
    "\n",
    "### ğŸ¯ LoRAé…ç½®è°ƒä¼˜\n",
    "1. **æé«˜æ¨ç†èƒ½åŠ›**:\n",
    "   ```python\n",
    "   LORA_CONFIG = {\n",
    "       \"r\": 32,  # å¢åŠ rankæé«˜è¡¨è¾¾èƒ½åŠ›\n",
    "       \"lora_alpha\": 64,  # å¯¹åº”è°ƒæ•´alpha\n",
    "       \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **èŠ‚çœæ˜¾å­˜**:\n",
    "   ```python\n",
    "   LORA_CONFIG = {\n",
    "       \"r\": 8,   # é™ä½rankèŠ‚çœæ˜¾å­˜\n",
    "       \"target_modules\": [\"q_proj\", \"v_proj\"],  # åªè®­ç»ƒattention\n",
    "   }\n",
    "   ```\n",
    "\n",
    "### ğŸš€ æ¨¡å‹é€‰æ‹©å»ºè®®\n",
    "- **qwen2.5-7b**: æœ€ä½³æ¨ç†èƒ½åŠ›ï¼Œéœ€è¦~14GBæ˜¾å­˜\n",
    "- **qwen2.5-3b**: å¹³è¡¡é€‰æ‹©ï¼Œéœ€è¦~10GBæ˜¾å­˜  \n",
    "- **qwen2.5-1.5b**: è½»é‡çº§ï¼Œéœ€è¦~8GBæ˜¾å­˜\n",
    "\n",
    "### ğŸ“ˆ è®­ç»ƒä¼˜åŒ–æŠ€å·§\n",
    "1. **å­¦ä¹ ç‡è°ƒä¼˜**: LoRAé€šå¸¸éœ€è¦2e-4åˆ°5e-4çš„è¾ƒé«˜å­¦ä¹ ç‡\n",
    "2. **æ•°æ®è´¨é‡**: ç¡®ä¿è®­ç»ƒæ•°æ®ä¸­çš„æ•°å­¦è®¡ç®—è¿‡ç¨‹æ­£ç¡®\n",
    "3. **è¯„ä¼°æŒ‡æ ‡**: é™¤äº†lossï¼Œè¿˜åº”è¯¥è®¡ç®—æ•°å­¦ç­”æ¡ˆçš„å‡†ç¡®ç‡\n",
    "4. **æ­£åˆ™åŒ–**: ä½¿ç”¨weight_decayé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "\n",
    "### âš¡ è¿›ä¸€æ­¥æå‡æ¨ç†èƒ½åŠ›çš„æ–¹æ³•\n",
    "1. **æ€ç»´é“¾(CoT)è®­ç»ƒ**: åœ¨æ•°æ®ä¸­æ˜ç¡®æ ‡æ³¨æ¯ä¸ªè®¡ç®—æ­¥éª¤\n",
    "2. **å·¥å…·è°ƒç”¨**: è®­ç»ƒæ¨¡å‹å­¦ä¼šè°ƒç”¨è®¡ç®—å™¨éªŒè¯ç»“æœ  \n",
    "3. **å¼ºåŒ–å­¦ä¹ **: ä½¿ç”¨RLHFè¿›ä¸€æ­¥ä¼˜åŒ–æ¨ç†å‡†ç¡®æ€§\n",
    "4. **é›†æˆå­¦ä¹ **: è®­ç»ƒå¤šä¸ªLoRAæ¨¡å‹ç„¶åé›†æˆ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
