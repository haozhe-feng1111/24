{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b09255-c46f-42b2-9e92-5e64861efa43",
   "metadata": {},
   "source": [
    "# Qwen2.5微调实战：24点游戏推理风格聊天\n",
    "\n",
    "[![](https://raw.githubusercontent.com/SwanHubX/assets/main/badge1.svg)](https://swanlab.cn/@ZeyiLin/qwen2.5-sft-24game/overview)\n",
    "\n",
    "- **基础模型**：[Qwen2.5-0.5B](https://modelscope.cn/models/Qwen/Qwen2.5-0.5B/summary)\n",
    "- **微调后模型**：[Qwen2.5-0.5b-24game-sft](https://modelscope.cn/models/testUser/Qwen2.5-0.5b-24game-sft/summary)\n",
    "- **数据集**：24点游戏推理数据集\n",
    "- **SwanLab**：[qwen2.5-sft-24game](https://swanlab.cn/@ZeyiLin/qwen2.5-sft-24game/runs/agps0dkifth5l1xytcdyk/chart)\n",
    "- **微调方式**：全参数微调、LoRA微调\n",
    "- **推理风格**：详细分析推理风格\n",
    "- **算力要求**：\n",
    "  - **全参数微调**：16GB显存\n",
    "  - **LoRA微调**：16GB显存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4fa4a-03a4-4bdb-b593-b50d2ebbb931",
   "metadata": {},
   "source": [
    "## 1. 安装环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42630f8a-e3d2-4972-9a44-a36aec69675f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swanlab in c:\\users\\10563\\anaconda3\\lib\\site-packages (0.6.7)\n",
      "Requirement already satisfied: boto3>=1.35.49 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (1.39.14)\n",
      "Requirement already satisfied: botocore in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (1.39.14)\n",
      "Requirement already satisfied: click in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (8.1.7)\n",
      "Requirement already satisfied: platformdirs>=4.2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (5.9.0)\n",
      "Requirement already satisfied: pydantic>=2.9.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.11.7)\n",
      "Requirement already satisfied: pyecharts>=2.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.0.8)\n",
      "Requirement already satisfied: pynvml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (12.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.28.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.6.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (13.7.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (75.1.0)\n",
      "Requirement already satisfied: swankit==0.2.4 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (0.2.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (2.2.3)\n",
      "Requirement already satisfied: wrapt>=1.17.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from swanlab) (1.17.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from boto3>=1.35.49->swanlab) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from boto3>=1.35.49->swanlab) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from botocore->swanlab) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->swanlab) (0.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pyecharts>=2.0.0->swanlab) (3.1.4)\n",
      "Requirement already satisfied: prettytable in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pyecharts>=2.0.0->swanlab) (3.16.0)\n",
      "Requirement already satisfied: simplejson in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pyecharts>=2.0.0->swanlab) (3.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.28.0->swanlab) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.28.0->swanlab) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.28.0->swanlab) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.6.0->swanlab) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.6.0->swanlab) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from click->swanlab) (0.4.6)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pynvml->swanlab) (12.575.51)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->swanlab) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore->swanlab) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from jinja2->pyecharts>=2.0.0->swanlab) (2.1.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\10563\\anaconda3\\lib\\site-packages (from prettytable->pyecharts>=2.0.0->swanlab) (0.2.5)\n",
      "Requirement already satisfied: modelscope==1.22.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (1.22.0)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from modelscope==1.22.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from modelscope==1.22.0) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from modelscope==1.22.0) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.25->modelscope==1.22.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.25->modelscope==1.22.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.25->modelscope==1.22.0) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->modelscope==1.22.0) (0.4.6)\n",
      "Requirement already satisfied: transformers in c:\\users\\10563\\anaconda3\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (0.34.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: datasets==3.2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (0.34.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from datasets==3.2.0) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from aiohttp->datasets==3.2.0) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets==3.2.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas->datasets==3.2.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas->datasets==3.2.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.16.0)\n",
      "Requirement already satisfied: peft in c:\\users\\10563\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (1.7.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from peft) (0.34.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
      "Requirement already satisfied: accelerate in c:\\users\\10563\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (0.34.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\10563\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\10563\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Requirement already satisfied: pandas in c:\\users\\10563\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10563\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: addict in c:\\users\\10563\\anaconda3\\lib\\site-packages (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install swanlab\n",
    "!pip install modelscope==1.22.0\n",
    "!pip install transformers\n",
    "!pip install datasets==3.2.0\n",
    "!pip install peft\n",
    "!pip install accelerate\n",
    "!pip install pandas\n",
    "!pip install addict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73ce7d-54a9-4928-9b27-c58c68c090d7",
   "metadata": {},
   "source": [
    "## 2. 下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0912c-ab6e-4d4d-95b5-ba9e11687d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据已准备完毕，训练和测试数据分别为 train_data.json 和 test_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac44ba5-45d2-4e43-a906-2e4421b72114",
   "metadata": {},
   "source": [
    "## 3. 登录SwanLab\n",
    "1. 前往[swanlab](https://swanlab.cn/space/~/settings)复制你的API Key，粘贴到下面的代码中\n",
    "2. 如果你不希望将登录信息保存到该计算机中，可将`save=True`去掉（每次运行训练需要重新执行下面的代码块）\n",
    "3. 训练项目名称已设置为 \"qwen3-sft-24game\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5cbc21-ae61-40fd-ae38-843b774fe82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import swanlab\n",
    "\n",
    "swanlab.login(api_key=\"G091Sp6B1xT6JfwsVZhCx\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43e7f4-976b-46ec-ab63-febeac40a3ce",
   "metadata": {},
   "source": [
    "## 4. 开启24点游戏模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c451e2e-8542-404c-9eab-8fd610bf8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import os\n",
    "import swanlab\n",
    "\n",
    "os.environ[\"SWANLAB_PROJECT\"]=\"qwen2.5-sft-24game\"\n",
    "PROMPT = \"你是一个24点游戏专家，擅长分析数字组合并找出运算方案。你需要根据用户给出的数字，详细分析解题思路和过程，最终给出能够得到24的运算方案。\"\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "swanlab.config.update({\n",
    "    \"model\": \"Qwen/Qwen2.5-0.5B\",\n",
    "    \"prompt\": PROMPT,\n",
    "    \"data_max_length\": MAX_LENGTH,\n",
    "    })\n",
    "\n",
    "def dataset_jsonl_transfer(origin_path, new_path):\n",
    "    \"\"\"\n",
    "    将原始数据集转换为大模型微调所需数据格式的新数据集\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # 读取原始JSON文件\n",
    "    with open(origin_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # 处理每个对话\n",
    "    for item in data:\n",
    "        conversation = item[\"messages\"]\n",
    "        user_content = conversation[0][\"content\"]  # 用户问题\n",
    "        assistant_content = conversation[1][\"content\"]  # 助手回答\n",
    "        \n",
    "        message = {\n",
    "            \"instruction\": PROMPT,\n",
    "            \"input\": user_content,\n",
    "            \"output\": assistant_content,\n",
    "        }\n",
    "        messages.append(message)\n",
    "\n",
    "    # 保存重构后的JSONL文件\n",
    "    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for message in messages:\n",
    "            file.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def process_func(example):\n",
    "    \"\"\"\n",
    "    将数据集进行预处理\n",
    "    \"\"\" \n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\n{PROMPT}<|im_end|>\\n<|im_start|>user\\n{example['input']}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = (\n",
    "        instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    )\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:  # 做一个截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}   \n",
    "\n",
    "\n",
    "def predict(messages, model, tokenizer):\n",
    "    device = \"cuda\"\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=MAX_LENGTH,\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response\n",
    "\n",
    "# 在modelscope上下载Qwen模型到本地目录下\n",
    "model_dir = snapshot_download(\"Qwen/Qwen2.5-0.5B\", cache_dir=\"./\", revision=\"master\")\n",
    "\n",
    "# Transformers加载模型权重\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model.enable_input_require_grads()  # 开启梯度检查点时，要执行该方法\n",
    "\n",
    "# 加载、处理数据集和测试集\n",
    "train_dataset_path = \"train_data.json\"\n",
    "test_dataset_path = \"test_data.json\"\n",
    "\n",
    "train_jsonl_new_path = \"train_format.jsonl\"\n",
    "test_jsonl_new_path = \"val_format.jsonl\"\n",
    "\n",
    "if not os.path.exists(train_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)\n",
    "if not os.path.exists(test_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(test_dataset_path, test_jsonl_new_path)\n",
    "\n",
    "# 得到训练集\n",
    "train_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)\n",
    "\n",
    "# 得到验证集\n",
    "eval_df = pd.read_json(test_jsonl_new_path, lines=True)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "eval_dataset = eval_ds.map(process_func, remove_columns=eval_ds.column_names)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen2.5-0.5B-24game\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=400,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"swanlab\",\n",
    "    run_name=\"qwen2.5-0.5B-24game\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 用测试集的前3条，主观看模型\n",
    "test_df = pd.read_json(test_jsonl_new_path, lines=True)[:3]\n",
    "\n",
    "test_text_list = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    instruction = row['instruction']\n",
    "    input_value = row['input']\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"}\n",
    "    ]\n",
    "\n",
    "    response = predict(messages, model, tokenizer)\n",
    "\n",
    "    response_text = f\"\"\"\n",
    "    Question: {input_value}\n",
    "\n",
    "    LLM:{response}\n",
    "    \"\"\"\n",
    "    \n",
    "    test_text_list.append(swanlab.Text(response_text))\n",
    "    print(response_text)\n",
    "\n",
    "swanlab.log({\"Prediction\": test_text_list})\n",
    "\n",
    "swanlab.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sl54o3ag9dq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA微调版本 - 支持更大模型在T4上训练\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from modelscope import snapshot_download, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import os\n",
    "import swanlab\n",
    "\n",
    "# =============配置参数============= \n",
    "# 模型选择：可以选择不同大小的模型\n",
    "MODEL_OPTIONS = {\n",
    "    \"qwen2.5-0.5b\": \"Qwen/Qwen2.5-0.5B\", \n",
    "    \"qwen2.5-1.5b\": \"Qwen/Qwen2.5-1.5B\",\n",
    "    \"qwen2.5-3b\": \"Qwen/Qwen2.5-3B\", \n",
    "    \"qwen2.5-7b\": \"Qwen/Qwen2.5-7B\"\n",
    "}\n",
    "\n",
    "# 选择要使用的模型\n",
    "SELECTED_MODEL = \"qwen2.5-7b\"  # 改为7B模型以获得更好的推理能力\n",
    "MODEL_NAME = MODEL_OPTIONS[SELECTED_MODEL]\n",
    "\n",
    "# 训练模式配置\n",
    "USE_LORA = True  # 是否使用LoRA微调\n",
    "USE_QUANTIZATION = True  # 是否使用量化（4bit）来进一步节省显存\n",
    "\n",
    "# LoRA配置\n",
    "LORA_CONFIG = {\n",
    "    \"r\": 16,  # LoRA rank，影响模型表达能力\n",
    "    \"lora_alpha\": 32,  # LoRA缩放参数\n",
    "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],  # Qwen2.5的attention和MLP层\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\"\n",
    "}\n",
    "\n",
    "# 训练参数配置  \n",
    "TRAINING_CONFIG = {\n",
    "    \"output_dir\": f\"./output/{SELECTED_MODEL}-24game-lora\",\n",
    "    \"per_device_train_batch_size\": 1,  # T4显存限制，使用小batch\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 8,  # 增加梯度累积来模拟更大batch\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 50,\n",
    "    \"logging_steps\": 10,\n",
    "    \"num_train_epochs\": 3,  # 增加训练轮数\n",
    "    \"save_steps\": 200,\n",
    "    \"learning_rate\": 2e-4,  # LoRA通常需要更高学习率\n",
    "    \"warmup_steps\": 100,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"save_on_each_node\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"dataloader_pin_memory\": False,  # 节省显存\n",
    "    \"report_to\": \"swanlab\",\n",
    "    \"run_name\": f\"{SELECTED_MODEL}-24game-lora\",\n",
    "}\n",
    "\n",
    "# 其他配置\n",
    "os.environ[\"SWANLAB_PROJECT\"] = \"qwen2.5-sft-24game-lora\"\n",
    "PROMPT = \"你是一个24点游戏专家，擅长分析数字组合并找出运算方案。你需要根据用户给出的数字，详细分析解题思路和过程，最终给出能够得到24的运算方案。\"\n",
    "MAX_LENGTH = 1024  # 减少序列长度节省显存\n",
    "\n",
    "# 更新SwanLab配置\n",
    "swanlab.config.update({\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"use_lora\": USE_LORA,\n",
    "    \"use_quantization\": USE_QUANTIZATION,\n",
    "    \"lora_config\": LORA_CONFIG,\n",
    "    \"training_config\": TRAINING_CONFIG,\n",
    "    \"data_max_length\": MAX_LENGTH,\n",
    "})\n",
    "\n",
    "print(f\"选择的模型: {MODEL_NAME}\")\n",
    "print(f\"使用LoRA: {USE_LORA}\")\n",
    "print(f\"使用量化: {USE_QUANTIZATION}\")\n",
    "print(f\"预计显存需求: ~12-14GB (相比全参数微调7B需要40GB+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apv1nf6a9yv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型加载和LoRA配置\n",
    "def load_model_and_tokenizer():\n",
    "    \"\"\"加载模型和tokenizer，支持量化和LoRA\"\"\"\n",
    "    \n",
    "    # 下载模型\n",
    "    print(f\"正在下载模型: {MODEL_NAME}\")\n",
    "    model_dir = snapshot_download(MODEL_NAME, cache_dir=\"./\", revision=\"master\")\n",
    "    \n",
    "    # 加载tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # 确保有pad_token\n",
    "    \n",
    "    # 配置量化（如果启用）\n",
    "    quantization_config = None\n",
    "    if USE_QUANTIZATION:\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,  # 4bit量化\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,  # 计算类型\n",
    "            bnb_4bit_quant_type=\"nf4\",  # 量化类型\n",
    "            bnb_4bit_use_double_quant=True,  # 双重量化，进一步节省显存\n",
    "        )\n",
    "        print(\"启用4bit量化\")\n",
    "    \n",
    "    # 加载模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",  # 自动分配GPU\n",
    "        torch_dtype=torch.bfloat16 if not USE_QUANTIZATION else None,\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"flash_attention_2\" if torch.cuda.is_available() else None,  # 使用Flash Attention加速\n",
    "    )\n",
    "    \n",
    "    # 准备LoRA微调\n",
    "    if USE_LORA:\n",
    "        print(\"配置LoRA...\")\n",
    "        \n",
    "        # 如果使用量化，需要准备模型\n",
    "        if USE_QUANTIZATION:\n",
    "            model = prepare_model_for_kbit_training(model)\n",
    "        \n",
    "        # 创建LoRA配置\n",
    "        lora_config = LoraConfig(**LORA_CONFIG)\n",
    "        \n",
    "        # 应用LoRA\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        \n",
    "        # 打印可训练参数统计\n",
    "        model.print_trainable_parameters()\n",
    "    else:\n",
    "        # 全参数微调需要启用输入梯度\n",
    "        model.enable_input_require_grads()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# 加载模型\n",
    "model, tokenizer = load_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hgknw2l18oh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理函数（与原版相同，但做了一些优化）\n",
    "def dataset_jsonl_transfer(origin_path, new_path):\n",
    "    \"\"\"将原始数据集转换为大模型微调所需数据格式的新数据集\"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    with open(origin_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    for item in data:\n",
    "        conversation = item[\"messages\"]\n",
    "        user_content = conversation[0][\"content\"]\n",
    "        assistant_content = conversation[1][\"content\"]\n",
    "        \n",
    "        message = {\n",
    "            \"instruction\": PROMPT,\n",
    "            \"input\": user_content,\n",
    "            \"output\": assistant_content,\n",
    "        }\n",
    "        messages.append(message)\n",
    "    \n",
    "    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for message in messages:\n",
    "            file.write(json.dumps(message, ensure_ascii=False) + \"\\\\n\")\n",
    "\n",
    "def process_func(example):\n",
    "    \"\"\"将数据集进行预处理，针对LoRA优化\"\"\"\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    \n",
    "    # 构建输入序列\n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\\\n{PROMPT}<|im_end|>\\\\n<|im_start|>user\\\\n{example['input']}<|im_end|>\\\\n<|im_start|>assistant\\\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    \n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    \n",
    "    # 截断到最大长度\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    \n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "def predict(messages, model, tokenizer):\n",
    "    \"\"\"预测函数，支持LoRA模型\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=512,  # 降低生成长度节省显存\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response\n",
    "\n",
    "print(\"数据处理函数已定义\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "et94fxq37xt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载和训练执行\n",
    "# 数据路径\n",
    "train_dataset_path = \"train_data.json\"\n",
    "test_dataset_path = \"test_data.json\"\n",
    "train_jsonl_new_path = \"train_format_lora.jsonl\"\n",
    "test_jsonl_new_path = \"val_format_lora.jsonl\"\n",
    "\n",
    "# 转换数据格式\n",
    "if not os.path.exists(train_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)\n",
    "if not os.path.exists(test_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(test_dataset_path, test_jsonl_new_path)\n",
    "\n",
    "# 加载和处理数据集\n",
    "print(\"加载训练数据...\")\n",
    "train_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)\n",
    "\n",
    "print(\"加载验证数据...\")\n",
    "eval_df = pd.read_json(test_jsonl_new_path, lines=True)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "eval_dataset = eval_ds.map(process_func, remove_columns=eval_ds.column_names)\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(eval_dataset)}\")\n",
    "\n",
    "# 创建训练参数\n",
    "args = TrainingArguments(**TRAINING_CONFIG)\n",
    "\n",
    "# 创建数据整理器\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# 创建训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "print(\"开始LoRA微调训练...\")\n",
    "print(f\"使用模型: {MODEL_NAME}\")\n",
    "print(f\"预计训练时间: ~2-4小时 (取决于数据量)\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 保存LoRA权重\n",
    "if USE_LORA:\n",
    "    print(\"保存LoRA权重...\")\n",
    "    model.save_pretrained(f\"./output/{SELECTED_MODEL}-24game-lora-weights\")\n",
    "    tokenizer.save_pretrained(f\"./output/{SELECTED_MODEL}-24game-lora-weights\")\n",
    "\n",
    "print(\"训练完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wdivfysgx9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试和效果验证\n",
    "print(\"开始测试微调后的模型...\")\n",
    "\n",
    "# 测试数据\n",
    "test_df = pd.read_json(test_jsonl_new_path, lines=True)[:3]\n",
    "test_text_list = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    instruction = row['instruction']\n",
    "    input_value = row['input']\n",
    "    expected_output = row['output']\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"}\n",
    "    ]\n",
    "\n",
    "    print(f\"\\\\n=== 测试 {index + 1} ===\")\n",
    "    print(f\"问题: {input_value}\")\n",
    "    \n",
    "    # 生成回答\n",
    "    response = predict(messages, model, tokenizer)\n",
    "    \n",
    "    print(f\"模型回答: {response}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response_text = f\"\"\"\n",
    "测试 {index + 1}:\n",
    "问题: {input_value}\n",
    "\n",
    "LoRA微调模型回答:\n",
    "{response}\n",
    "\n",
    "原始训练数据答案:\n",
    "{expected_output[:200]}...\n",
    "\"\"\"\n",
    "    \n",
    "    test_text_list.append(swanlab.Text(response_text))\n",
    "\n",
    "# 记录到SwanLab\n",
    "swanlab.log({\"LoRA_Predictions\": test_text_list})\n",
    "\n",
    "# 显存使用情况\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\\\n当前GPU显存使用: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"峰值GPU显存使用: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "print(\"\\\\n=== LoRA微调训练总结 ===\")\n",
    "print(f\"基础模型: {MODEL_NAME}\")\n",
    "print(f\"训练方式: {'LoRA微调' if USE_LORA else '全参数微调'}\")\n",
    "print(f\"是否量化: {USE_QUANTIZATION}\")\n",
    "print(f\"LoRA rank: {LORA_CONFIG['r']}\")\n",
    "print(f\"目标模块: {LORA_CONFIG['target_modules']}\")\n",
    "print(f\"预期效果: 7B模型应该具备更强的数学推理能力\")\n",
    "\n",
    "swanlab.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vxek8bcjvgg",
   "metadata": {},
   "source": [
    "## LoRA微调使用指南和优化建议\n",
    "\n",
    "### 📊 显存对比\n",
    "- **全参数微调7B**: 需要40GB+ 显存  \n",
    "- **LoRA + 4bit量化**: 仅需12-14GB显存 ✅ \n",
    "- **T4 GPU**: 16GB显存 ✅ 完全可用\n",
    "\n",
    "### 🎯 LoRA配置调优\n",
    "1. **提高推理能力**:\n",
    "   ```python\n",
    "   LORA_CONFIG = {\n",
    "       \"r\": 32,  # 增加rank提高表达能力\n",
    "       \"lora_alpha\": 64,  # 对应调整alpha\n",
    "       \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **节省显存**:\n",
    "   ```python\n",
    "   LORA_CONFIG = {\n",
    "       \"r\": 8,   # 降低rank节省显存\n",
    "       \"target_modules\": [\"q_proj\", \"v_proj\"],  # 只训练attention\n",
    "   }\n",
    "   ```\n",
    "\n",
    "### 🚀 模型选择建议\n",
    "- **qwen2.5-7b**: 最佳推理能力，需要~14GB显存\n",
    "- **qwen2.5-3b**: 平衡选择，需要~10GB显存  \n",
    "- **qwen2.5-1.5b**: 轻量级，需要~8GB显存\n",
    "\n",
    "### 📈 训练优化技巧\n",
    "1. **学习率调优**: LoRA通常需要2e-4到5e-4的较高学习率\n",
    "2. **数据质量**: 确保训练数据中的数学计算过程正确\n",
    "3. **评估指标**: 除了loss，还应该计算数学答案的准确率\n",
    "4. **正则化**: 使用weight_decay防止过拟合\n",
    "\n",
    "### ⚡ 进一步提升推理能力的方法\n",
    "1. **思维链(CoT)训练**: 在数据中明确标注每个计算步骤\n",
    "2. **工具调用**: 训练模型学会调用计算器验证结果  \n",
    "3. **强化学习**: 使用RLHF进一步优化推理准确性\n",
    "4. **集成学习**: 训练多个LoRA模型然后集成"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
